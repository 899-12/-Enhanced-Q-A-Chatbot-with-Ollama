
# Enhanced Q&A Chatbot with Ollama  

This project is a Q&A chatbot leveraging open-source LLMs powered by **Ollama**. It uses the LangChain framework for seamless integration of prompt engineering, output parsing, and efficient model interaction. Built with Streamlit, the chatbot offers an interactive and user-friendly interface for handling real-time queries.

---

## ðŸš€ Features  
- **Open-Source LLMs:** Supports integration with models like `mistral` via Ollama.  
- **LangChain Integration:** Provides dynamic prompt engineering and structured output parsing.  
- **Customizable Parameters:** Users can configure temperature and token limits.  
- **Streamlit Interface:** A responsive web-based UI for real-time Q&A.  

---

## ðŸ“‹ Table of Contents  
- [Features](#-features)  
- [Requirements](#-requirements)  
- [Installation](#-installation)  
- [Usage](#-usage)  
- [Technologies Used](#-technologies-used)  


---

## ðŸ›  Requirements  
- Python 3.8+  
- Libraries: `streamlit`, `openai`, `langchain_openai`, `langchain_core`, `langchain_community`, `python-dotenv`  
- Ollama installed locally  

---

## ðŸ“¦ Installation  

1. **Clone the Repository:**  
   ```bash
   git clone https://github.com/username/repo-name.git
   cd repo-name
